{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f1e3df7499775c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Processament i visualització"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "490afe0e2c30ddc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T11:20:16.131136922Z",
     "start_time": "2023-12-20T11:20:15.013171687Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import io\n",
    "import os\n",
    "import tqdm\n",
    "import requests\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from PIL import Image\n",
    "from pprint import pprint\n",
    "import pyarrow.parquet as pq\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bcb83ce7183037",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Scrapping the XAC database\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "webdriver.firefox.marionette=False\n",
    "# El rows = 1000 travieso és per aprofitar el bug\n",
    "BASE_ARXIU = 'https://arxiusenlinia.cultura.gencat.cat'\n",
    "QUERY_GLOBAL = BASE_ARXIU +'/#/cercaavancada/cerca'\n",
    "\n",
    "option = webdriver.ChromeOptions()\n",
    "option.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "option.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "#For ChromeDriver version 79.0.3945.16 or over\n",
    "option.add_argument('--disable-blink-features=AutomationControlled')\n",
    "\n",
    "option.add_argument(\"window-size=1280,800\")\n",
    "option.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36\")\n",
    "\n",
    "DRIVERPATH = 'geckodriver' \n",
    "OUPATH = 'arxiu/'\n",
    "DRIVER = webdriver.Chrome(options=option)\n",
    "DRIVER.get(QUERY_GLOBAL)\n",
    "\n",
    "DRIVER.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "\n",
    "def check_if_loading():\n",
    "    try:\n",
    "        return DRIVER.find_element(By.CLASS_NAME, 'spinner-container').is_displayed\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "\n",
    "def scrap():\n",
    "    while True:\n",
    "        # while check_if_loading(): pass\n",
    "    \n",
    "        for element in BeautifulSoup(DRIVER.page_source, features=\"html.parser\").find('table').find_all(class_='row'):\n",
    "            soup_elelment = element # METADATA FROM HERE\n",
    "            photo = soup_elelment.find('img', class_ = 'image-list-item-responsive')\n",
    "            if photo is not None:\n",
    "                if photo['src'] in visited: continue # Cal fer-ho en dos nivells perque si és None no és iterable per tant no té \"in\" \n",
    "            desc = soup_elelment.find_all(class_ = 'contingut-nom-metadada')\n",
    "            if not len(desc): continue\n",
    "            try:\n",
    "                date = desc[2].find_next_siblings('span')[0]\n",
    "            except IndexError:\n",
    "                date = \"<span>1/1/0000</span>\" # Placeholder\n",
    "            desc = desc[-1].find_next_siblings('span')\n",
    "            title = soup_elelment.find(class_ = 'titol-text-resultats')\n",
    "            if photo is not None and title is not None and desc is not None:\n",
    "                photo = photo['src']\n",
    "                title = title\n",
    "                desc = desc[0]\n",
    "                date = date\n",
    "    \n",
    "                data = {\n",
    "                    'image': str(photo),\n",
    "                    'caption': str(title).replace('\\n', ' '),\n",
    "                    'desc': str(desc).replace('\\n', ' '),\n",
    "                    'date': str(date)\n",
    "                }\n",
    "                visited.add(photo)\n",
    "                \n",
    "                CSV.write(\"\\n\" + '\\t'.join(list(data.values()))) # Separat per tabulacions per evitar problemes de parsing amb les commes de les fotos i descripcions\n",
    "        succeed = False\n",
    "        while not succeed:\n",
    "            # De vegades el botó de següent está oclòs ja que BS4 va més ràpid que selenium carregant les coses, per algun motiu comprobar el display no funciona\n",
    "            try:\n",
    "                next = WebDriverWait(DRIVER, 10).until(\n",
    "                    EC.element_to_be_clickable((By.CLASS_NAME, 'ui-paginator-next'))\n",
    "                )\n",
    "                next.click()\n",
    "                succeed = True\n",
    "            except: pass\n",
    "            \n",
    "\n",
    "input(\"Press enter to proceed... \") # Cal inserir la cerca manualment perque funciona desde front-end; tirem de selenium\n",
    "CSV = open('imatges2.tsv', 'w')\n",
    "CSV.write('\\t'.join(['url', 'caption', 'desc', 'date']))\n",
    "visited = set()\n",
    "scrap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69921e221747fac6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Functions to download images from XAC (previously scrapped) and resize them\n",
    "\n",
    "def download_images(data, data_location, check_unique=True, train_test_split=0.8):\n",
    "    \"\"\"\n",
    "\n",
    "    Args:\n",
    "        data: File name with the url, captions and description of the images\n",
    "        data_location: Directory name where the data is stored\n",
    "        check_unique: Bool to check unique captions (deletes duplicate captions)\n",
    "        train_test_split: Ratio of images for train\n",
    "\n",
    "    \"\"\"\n",
    "    train_dir = os.path.join(data_location, 'train')\n",
    "    test_dir = os.path.join(data_location, 'test')\n",
    "\n",
    "    # Create dataframe for images\n",
    "    images_df = pd.read_csv(os.path.join(data_location, data), sep='\\t', encoding=\"ISO-8859-1\")\n",
    "\n",
    "    # Create captions files\n",
    "    with open(os.path.join(data_location, \"captions_train_raw.tsv\"), \"w\") as f:\n",
    "        f.write(\"image\\tcaption\\n\")\n",
    "\n",
    "    with open(os.path.join(data_location, \"captions_test_raw.tsv\"), \"w\") as f:\n",
    "        f.write(\"image\\tcaption\\n\")\n",
    "\n",
    "    id = 0\n",
    "    unique_captions = set()\n",
    "    if check_unique:\n",
    "        # Download images from url and fill captions file\n",
    "        for url, caption in zip(images_df.url.values, images_df.caption.values):\n",
    "            name = os.path.split(url)[1]\n",
    "            caption = caption[35:-7]\n",
    "            if caption in unique_captions:\n",
    "                id += 1\n",
    "                continue\n",
    "            unique_captions.add(caption)\n",
    "            r = requests.get(url, stream=True)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                i = Image.open(io.BytesIO(r.content))\n",
    "\n",
    "                if np.random.rand() < train_test_split:\n",
    "                    i.save(os.path.join(train_dir, name), quality=95)\n",
    "                    with open(os.path.join(data_location, \"captions_train_raw.tsv\"), \"a\") as f:\n",
    "                        f.write(name + \"\\t\" + caption + \"\\n\")\n",
    "                else:\n",
    "                    i.save(os.path.join(test_dir, name), quality=95)\n",
    "                    with open(os.path.join(data_location, \"captions_test_raw.tsv\"), \"a\") as f:\n",
    "                        f.write(name + \"\\t\" + caption + \"\\n\")\n",
    "\n",
    "            if (id % 100) == 0:\n",
    "                print(\n",
    "                    f\"Progress: {id}/{len(images_df.url.values)} with {len(unique_captions)} unique captions so far.\\n\")\n",
    "            id += 1\n",
    "    else:\n",
    "        # Download images from url and fill captions file\n",
    "        for url, caption in zip(images_df.url.values, images_df.caption.values):\n",
    "            name = os.path.split(url)[1]\n",
    "            caption = caption[35:-7]\n",
    "            r = requests.get(url, stream=True)\n",
    "\n",
    "            if r.status_code == 200:\n",
    "                i = Image.open(io.BytesIO(r.content))\n",
    "\n",
    "                if np.random.rand() < train_test_split:\n",
    "                    i.save(os.path.join(train_dir, name), quality=95)\n",
    "                    with open(os.path.join(data_location, \"captions_train_raw.tsv\"), \"a\") as f:\n",
    "                        f.write(name + \"\\t\" + caption + \"\\n\")\n",
    "                else:\n",
    "                    i.save(os.path.join(test_dir, name), quality=95)\n",
    "                    with open(os.path.join(data_location, \"captions_test_raw.tsv\"), \"a\") as f:\n",
    "                        f.write(name + \"\\t\" + caption + \"\\n\")\n",
    "\n",
    "            if (id % 100) == 0:\n",
    "                print(f\"Progress: {id}/{len(images_df.url.values)} \\n\")\n",
    "            id += 1\n",
    "    print('Finished downloading all images')\n",
    "\n",
    "\n",
    "def resize_images(image_dir, output_dir, size):\n",
    "    \"\"\"Resize the images in 'image_dir' and save into 'output_dir'.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    images = os.listdir(image_dir)\n",
    "    num_images = len(images)\n",
    "    for i, image in enumerate(images):\n",
    "        with open(os.path.join(image_dir, image), 'r+b') as f:\n",
    "            with Image.open(f) as img:\n",
    "                img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "                img.save(os.path.join(output_dir, image), img.format)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"[{}/{}] Resized the images and saved into '{}'.\"\n",
    "                  .format(i + 1, num_images, output_dir))\n",
    "\n",
    "\n",
    "def resize_images_dew(data, output_dir, root_dir, size):\n",
    "    \"\"\"Resize the images in 'image_dir' and save into 'output_dir'.\"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    if type(data) == tuple:\n",
    "        data_0 = pd.read_csv(data[0], header=None, sep=',')\n",
    "        data_1 = pd.read_csv(data[1], header=None, sep=',')\n",
    "        data = pd.concat([data_0, data_1])\n",
    "        del data_0, data_1\n",
    "    else:\n",
    "        data = pd.read_csv(data, header=None, sep=',')\n",
    "    names = data[1]\n",
    "\n",
    "    num_images = len(names)\n",
    "    for i, image in enumerate(names):\n",
    "        image = str(image)\n",
    "        with open(os.path.join(root_dir, image[:1], image[1:3], image + '.jpg'), 'rb') as f:\n",
    "            with Image.open(f) as img:\n",
    "                img = img.resize(size, Image.Resampling.LANCZOS)\n",
    "                img.save(os.path.join(output_dir, image + '.jpg'), img.format)\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(\"[{}/{}] Resized the images and saved into '{}'.\"\n",
    "                  .format(i + 1, num_images, output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7425fd21bcc353",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Distribució d'idiomes del subset sencer\n",
    "\n",
    "filename = \"part-00000-fc82da14-99c9-4ff6-ab6a-ac853ac82819-c000.snappy.parquet\"\n",
    "print(pq.ParquetFile(filename).schema)\n",
    "df = pq.read_table(filename).to_pandas()\n",
    "\n",
    "langs = dict()\n",
    "for el in df['LANGUAGE'].values:\n",
    "    print(el)\n",
    "    if el not in langs.keys():\n",
    "        langs[el] = 1\n",
    "    else:\n",
    "        langs[el] += 1\n",
    "\n",
    "pprint(langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aad0c06ce5de2d5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Netejar train original per incloure només imatges decarregades\n",
    "\n",
    "df = pd.read_csv('/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/laion/train.csv', sep='\\t')\n",
    "imgs = os.listdir('/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/laion/img_size/')\n",
    "\n",
    "imgs = set(imgs)\n",
    "langs = dict()\n",
    "rmv = list()\n",
    "\n",
    "with tqdm.tqdm(total=len(imgs)) as pbar:\n",
    "    for i, id, lang in zip(df.index, df['SAMPLE_ID'], df['LANGUAGE']):\n",
    "        if str(id) + '.jpg' in imgs:\n",
    "            if lang not in langs.keys():\n",
    "                langs[lang] = 1\n",
    "            else:\n",
    "                langs[lang] += 1\n",
    "            pbar.update(1)\n",
    "        else:\n",
    "            rmv.append(i)\n",
    "\n",
    "pprint(langs)\n",
    "\n",
    "df = df.drop(rmv)\n",
    "df.to_csv('clean_train.csv', sep='\\t')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5695cadcb639ba",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Canviar format caption\n",
    "\n",
    "file_path = '/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/laion/captions.jsonl'\n",
    "caps = pd.read_json(path_or_buf=file_path, lines=True)\n",
    "\n",
    "langs = caps.columns[2:]\n",
    "caps_2 = list()\n",
    "\n",
    "for i in caps.index:\n",
    "    for lang in langs:\n",
    "        row = {'image/key': caps['image/key'].iloc[i], 'image/locale': caps['image/locale'].iloc[i],\n",
    "               'caption': caps[lang].iloc[i]['caption'][0], 'lang': lang}\n",
    "        caps_2.append(row)\n",
    "        if len(caps[lang].iloc[i]['caption']) > 1:\n",
    "            row = {'image/key': caps['image/key'].iloc[i], 'image/locale': caps['image/locale'].iloc[i],\n",
    "                   'caption': caps[lang].iloc[i]['caption'][1], 'lang': lang}\n",
    "            caps_2.append(row)\n",
    "\n",
    "df = pd.DataFrame(caps_2)\n",
    "\n",
    "df.to_csv('captions.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f47da8f9132b5",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Anàlisi de les coincidències entre etiquetatges de llenguatges i similarity\n",
    "\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "\n",
    "\n",
    "file_path = 'final_train.csv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "langs = np.unique(df['LANGUAGE'])\n",
    "print(len(langs))\n",
    "unknown = ['co', 'fy', 'gd', 'ha', 'iw', 'mi', 'my', 'sd', 'sm', 'sn', 'so', 'st', 'su', 'tg', 'uz', 'yi', 'yo']\n",
    "ids = [i for i, x in enumerate(langs) if x in unknown]\n",
    "langs = np.delete(langs, ids)\n",
    "langs = np.append(langs, 'en')\n",
    "print(langs)\n",
    "\n",
    "identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "identifier.set_languages(langs)\n",
    "print(identifier.classify(\"This is a test\")[0])\n",
    "\n",
    "\n",
    "similarity27 = df[df['similarity'] > 0.27]\n",
    "similarity28 = df[df['similarity'] > 0.28]\n",
    "similarity29 = df[df['similarity'] > 0.29]\n",
    "similarity30 = df[df['similarity'] > 0.3]\n",
    "\n",
    "print('0.27:', len(similarity27),\n",
    "      similarity27['TEXT'].head(30),\n",
    "      '\\n0.28:', len(similarity28),\n",
    "      similarity28['TEXT'].head(30),\n",
    "      '\\n0.29:', len(similarity29),\n",
    "      similarity29['TEXT'].head(30),\n",
    "      '\\n0.30:', len(similarity30),\n",
    "      similarity30['TEXT'].head(30))\n",
    "\n",
    "preds = [identifier.classify(text)[0] for text in df['TEXT']]\n",
    "origi = df['LANGUAGE']\n",
    "cnt_ori = dict(Counter(origi))\n",
    "cnt_ori['en'] = 0\n",
    "\n",
    "cnt_prd = dict(Counter(preds))\n",
    "for lang in unknown:\n",
    "    cnt_prd[lang] = 0\n",
    "\n",
    "cnt_prd = dict(sorted(cnt_prd.items(), key=lambda x: x[1], reverse=True))\n",
    "cnt_ori = dict(sorted(cnt_ori.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "df_prd = pd.DataFrame(cnt_prd.items(), columns=['language', 'count'])\n",
    "df_ori = pd.DataFrame(cnt_ori.items(), columns=['language', 'count'])\n",
    "\n",
    "en_pred = [pred == 'en' for pred in preds]\n",
    "accuracy = [pred == org for pred, org in zip(preds, origi)]\n",
    "print(\"Percentatge d'anglès:\", sum(en_pred)/len(en_pred)*100,\n",
    "      \"Precisió respecte l'original:\", sum(accuracy)/len(accuracy)*100)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(17, 8))\n",
    "\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.barplot(x=\"language\", y=\"count\", data=df_ori,\n",
    "            label=\"Original\", color=\"b\")\n",
    "\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.barplot(x=\"language\", y=\"count\", data=df_prd,\n",
    "            alpha=0.5, label=\"Predicted\", color=\"r\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "plt.xticks(rotation=90)\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(title=\"Language labels accuracy\", ylabel=\"Count\", xlabel=\"Languages\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "\n",
    "f.savefig('comparison.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d18bf1be13eab3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Anàlisi de les coincidències entre etiquetatges de llenguatges i similarity\n",
    "\n",
    "from langid.langid import LanguageIdentifier, model\n",
    "from collections import defaultdict\n",
    "\n",
    "file_path = 'final_train.csv'\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "langs = np.unique(df['LANGUAGE'])\n",
    "print(len(langs))\n",
    "unknown = ['co', 'fy', 'gd', 'ha', 'iw', 'mi', 'my', 'sd', 'sm', 'sn', 'so', 'st', 'su', 'tg', 'uz', 'yi', 'yo']\n",
    "ids = [i for i, x in enumerate(langs) if x in unknown]\n",
    "langs = np.delete(langs, ids)\n",
    "langs = np.append(langs, 'en')\n",
    "print(langs)\n",
    "all_langs = np.append(langs, unknown)\n",
    "\n",
    "identifier = LanguageIdentifier.from_modelstring(model, norm_probs=True)\n",
    "identifier.set_languages(langs)\n",
    "print(identifier.classify(\"This is a test\")[0])\n",
    "\n",
    "preds = [identifier.classify(text)[0] for text in df['TEXT']]\n",
    "origi = df['LANGUAGE']\n",
    "similarity = np.array(df['similarity'])\n",
    "\n",
    "idx_preds = defaultdict(list)\n",
    "for i, lang in enumerate(preds):\n",
    "    idx_preds[lang].append(i)\n",
    "\n",
    "idx_origi = defaultdict(list)\n",
    "for i, lang in enumerate(origi):\n",
    "    idx_origi[lang].append(i)\n",
    "\n",
    "mean_preds = {lang: np.mean(similarity[i]) for lang, i in idx_preds.items()}\n",
    "mean_origi = {lang: np.mean(similarity[i]) for lang, i in idx_origi.items()}\n",
    "\n",
    "df_prd = pd.DataFrame(mean_preds.items(), columns=['language', 'clip'])\n",
    "df_ori = pd.DataFrame(mean_origi.items(), columns=['language', 'clip'])\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(17, 8))\n",
    "\n",
    "# Plot the total crashes\n",
    "sns.set_color_codes(\"pastel\")\n",
    "sns.catplot(data=df_ori, x='language', y='clip',\n",
    "            label=\"Original\", color=\"b\")\n",
    "\n",
    "# Plot the crashes where alcohol was involved\n",
    "sns.set_color_codes(\"muted\")\n",
    "sns.catplot(data=df_prd, x='language', y='clip',\n",
    "            alpha=0.8, label=\"Predicted\", color=\"r\")\n",
    "\n",
    "# Add a legend and informative axis label\n",
    "plt.xticks(rotation=90)\n",
    "ax.legend(ncol=2, loc=\"lower right\", frameon=True)\n",
    "ax.set(title=\"Language labels similarity\", ylabel=\"CLIP similarity mean\", xlabel=\"Languages\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "f.savefig('similarity.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f947d798b869a03",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix llenguatges\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "\n",
    "df = pd.read_csv('preds.csv', sep='\\t')\n",
    "labels = np.unique(df['prediccio'])\n",
    "matplotlib.rcParams['figure.figsize'] = 19, 15\n",
    "cm = confusion_matrix(df['original'], df['prediccio'], labels=labels)\n",
    "\n",
    "magma = matplotlib.colormaps['magma'].reversed()\n",
    "cmap = ListedColormap(magma(np.linspace(0.1, 1, 256)))\n",
    "cmap.set_bad('white')      # color of mask on heatmap\n",
    "cmap.set_under('white')    # color of mask on cbar\n",
    "\n",
    "sns.heatmap(cm,\n",
    "    cmap=cmap, vmin=5,            # set cbar range from 0.5 to 1\n",
    "    mask=cm < 5,                  # use \"bad\" color for thresholded values\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    cbar_kws={'extend': 'min'})     # extend cbar to show \"under\" color\n",
    "\n",
    "plt.savefig('confusionmatrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7499a1a4776b77",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix percentatges\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "df = pd.read_csv('preds.csv', sep='\\t')\n",
    "total = pd.read_csv('/data2fast/users/esanchez/laion/clean_train.csv', sep='\\t')\n",
    "\n",
    "labels_pred = set(np.unique(df['prediccio']))\n",
    "labels_origi = np.unique(df['original'])\n",
    "labels_pred.update(labels_origi)\n",
    "labels = sorted(list(labels_pred))\n",
    "matplotlib.rcParams['figure.figsize'] = 19, 15\n",
    "cm = confusion_matrix(df['original'], df['prediccio'], labels=labels)\n",
    "cm = np.array([(row / np.sum(row)) if np.sum(row) > 0 else row for row in cm])\n",
    "\n",
    "\n",
    "threshold = 0\n",
    "del_list = list()\n",
    "for i, row in enumerate(cm):\n",
    "    if row[i] < threshold:\n",
    "        del_list.append(i)\n",
    "\n",
    "del_list = list(reversed(del_list))\n",
    "cm = np.delete(cm, del_list, 0)\n",
    "cm = np.delete(cm, del_list, 1)\n",
    "labels = np.delete(labels, del_list)\n",
    "\n",
    "magma = matplotlib.colormaps['Blues']\n",
    "cmap = ListedColormap(magma(np.linspace(0.1, 1, 256)))\n",
    "cmap.set_bad('white')      # color of mask on heatmap\n",
    "cmap.set_under('white')    # color of mask on cbar\n",
    "\n",
    "sns.heatmap(cm,\n",
    "    cmap=cmap, vmin=0.0001,            # set cbar range from 0.5 to 1\n",
    "    mask=cm == 0,                  # use \"bad\" color for thresholded values\n",
    "    xticklabels=labels,\n",
    "    yticklabels=labels,\n",
    "    cbar_kws={'extend': 'min'})     # extend cbar to show \"under\" color\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('Laion labels')\n",
    "plt.savefig('confusionmatrix_0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacd90922f0fc5f",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Crear dataset de coincidències\n",
    "\n",
    "df = pd.read_csv('preds.csv', sep='\\t')\n",
    "total = pd.read_csv('/data2fast/users/esanchez/laion/clean_train.csv', sep='\\t')\n",
    "df = df[df['prediccio'] == df['original']]\n",
    "\n",
    "total = total.iloc[df.index]\n",
    "print(total)\n",
    "\n",
    "names = total.columns\n",
    "unnamed = [name for name in names if name[:3] == 'Unn']\n",
    "total = total.drop(columns=unnamed)\n",
    "total.to_csv('train_coincidences.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b83e560c101d60",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Fer recompte de les llengües\n",
    "\n",
    "df = pd.read_csv('train_coincidences.csv', sep='\\t')\n",
    "cnt = dict(Counter(df['LANGUAGE']))\n",
    "\n",
    "cnt = dict(sorted(cnt.items(), key=lambda x: x[0]))\n",
    "df_cnt = pd.DataFrame(cnt.items(), columns=['language', 'count'])\n",
    "\n",
    "df_cnt.to_csv('count.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1e4c93130a1e44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('count.csv')\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "sns.set_theme(rc={'figure.figsize': (15, 8)})\n",
    "\n",
    "ax = sns.barplot(df, x=\"language\", y=\"count\", errorbar=None)\n",
    "ax.bar_label(ax.containers[0], fontsize=10, rotation=90)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=60)\n",
    "ax.set(ylim=(0, 1.6e6), ylabel=\"Amount of samples\", xlabel=\"Language codes\")\n",
    "sns.despine(left=True, bottom=True)\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig('laion_count.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48d87d8aec56980",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Crear arxiu scenes del dataset DeBoer\n",
    "\n",
    "path = '/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/deboer/scene_detection_set'\n",
    "classes = next(os.walk(path))[1]\n",
    "dirs = [os.path.join(path, fold) for fold in classes]\n",
    "\n",
    "numberOfRows = len([[name for name in os.listdir(fold) if os.path.isfile(name)] for fold in dirs])\n",
    "print(numberOfRows)\n",
    "\n",
    "# dsp anar afegint les dades per carpetes (escenes)\n",
    "df = pd.DataFrame(index=np.arange(0, numberOfRows), columns=['file', 'scene'])\n",
    "i = 0\n",
    "for name in classes:\n",
    "    dir_path = os.path.join(path, name)\n",
    "    new = [{'file': file, 'scene': name} for file in os.listdir(dir_path) if os.path.isfile(file)]\n",
    "    df.iloc[i:i+len(new)] = new\n",
    "    i += len(new)\n",
    "\n",
    "df.to_csv('scenes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27d11c28e95d510",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Separar dataset en train i test\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/deboer/scenes.csv\")\n",
    "df = df[['file', 'scene']]\n",
    "\n",
    "train = df.copy()\n",
    "test = None\n",
    "scenes = np.unique(df.scene)\n",
    "del_rows = list()\n",
    "\n",
    "split = 0.05\n",
    "for scene in scenes:\n",
    "    total = np.sum(df.scene == scene)\n",
    "    n_test = int(total * split)\n",
    "\n",
    "    idx = np.random.choice(total, size=n_test, replace=False)\n",
    "    rows = df[df.scene == scene].iloc[idx]\n",
    "\n",
    "    if test is None:\n",
    "        test = pd.DataFrame(rows)\n",
    "    else:\n",
    "        test = pd.concat([test, rows], ignore_index=True)\n",
    "    del_rows.extend(rows.index)\n",
    "\n",
    "test.reset_index(inplace=True, drop=True)\n",
    "train.drop(del_rows, inplace=True)\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "\n",
    "test.to_csv(\"/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/deboer/test.csv\")\n",
    "train.to_csv(\"/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/deboer/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6a0c6c6996f4d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Separar dataset en train i test\n",
    "\n",
    "split = 0.05\n",
    "\n",
    "df = pd.read_csv('captions.tsv', sep='\\t')\n",
    "total = len(df)\n",
    "\n",
    "idx = np.sort(np.random.choice(total, int(total*split), replace=False))\n",
    "\n",
    "test = df.iloc[idx]\n",
    "\n",
    "idx_neg = [i not in idx for i in range(total)]\n",
    "\n",
    "train = df[idx_neg]\n",
    "\n",
    "train.to_csv('train.tsv', sep='\\t', index=False)\n",
    "test.to_csv('test.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27478918-586f-4f0d-bac5-32c5b81a8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afegir NER a dades XAC \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"projecte-aina/roberta-base-ca-cased-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"projecte-aina/roberta-base-ca-cased-ner\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def get_token(token):\n",
    "    split = token.split('-')\n",
    "    if split[0] == \"I\":\n",
    "        return \"\"\n",
    "    type_token = split[-1].lower()\n",
    "    return \"<\" + type_token + \">\"\n",
    "    \n",
    "class SentenceGetter:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        i = 0\n",
    "        while i < len(self.data['caption']):\n",
    "            yield self.data.iloc[i:i+self.batch_size]\n",
    "            i += self.batch_size\n",
    "\n",
    "df = pd.read_csv(\"/data2fast/users/esanchez/xac/captions_4.tsv\", sep=\"\\t\")\n",
    "df = df[[\"image\", \"caption\"]]\n",
    "\n",
    "df_out = {'image':list(), 'caption':list()}\n",
    "dataloader = SentenceGetter(df, 32)\n",
    "\n",
    "for batch in tqdm.tqdm(dataloader):\n",
    "    images = list(batch['image'])\n",
    "    frases = list(batch['caption'])\n",
    "    maskeds = nlp(frases)\n",
    "    \n",
    "    for image, frase, masked in zip(images, frases, maskeds):\n",
    "        output = [i for i in frase]\n",
    "        \n",
    "        masked = reversed(masked)\n",
    "        \n",
    "        for token in masked:\n",
    "            pre = output[:token['start']]\n",
    "            entity = get_token(token['entity'])\n",
    "            post = output[token['end']:]\n",
    "            output = pre + [entity] + post\n",
    "        output = ''.join(output)\n",
    "        df_out['image'].append(image)\n",
    "        df_out['caption'].append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691b13b4ebc3f39",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Afegir NER a dades LAION (es, de, nl)\n",
    "\n",
    "import pandas as pd\n",
    "import flair\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def space_before(caption, tokens):\n",
    "    j = 1\n",
    "    space = list()\n",
    "    caption = caption[j:]\n",
    "    for idx, token in enumerate(tokens[1:]):\n",
    "        j = caption.find(token.text)\n",
    "        space.append(caption[j-1] == \" \")\n",
    "        j += len(token.text)\n",
    "        caption = caption[j:]\n",
    "    space.append(False)\n",
    "    return space\n",
    "\n",
    "\n",
    "def ner_sentence(caption, tagger):\n",
    "    sent = Sentence(caption)\n",
    "    tagger.predict(sent)\n",
    "\n",
    "    space = space_before(caption, sent.tokens)\n",
    "\n",
    "    span = list()\n",
    "    labels = list()\n",
    "    for label in sent.get_labels():\n",
    "        aux = label.unlabeled_identifier.split(\"[\")[1].split(\":\")\n",
    "        ll = [int(aux[0])]\n",
    "        aux = aux[1].split(\"]\")\n",
    "        ll.append(int(aux[0]))\n",
    "        span.append(ll)\n",
    "        labels.append(label.value)\n",
    "\n",
    "    span.reverse()\n",
    "    labels.reverse()\n",
    "\n",
    "    caption = [t.text for t in sent.tokens]\n",
    "    aux = list()\n",
    "    for ran, label in zip(span, labels):\n",
    "        caption[ran[0]] = token[label]\n",
    "        caption[ran[0] + 1:ran[1]] = ''\n",
    "        if ran[1] - ran[0] > 1:\n",
    "            aux.extend(range(ran[1] - 1, ran[0], -1))\n",
    "\n",
    "    for elem in aux:\n",
    "        try:\n",
    "            space.pop(elem)\n",
    "        except IndexError:\n",
    "            print(\"caption\", caption)\n",
    "            print(\"labels\", sent.get_labels())\n",
    "            print(\"space\", space)\n",
    "            print(\"aux\", aux)\n",
    "            print(\"unlabeled_identifier\", sent.unlabeled_identifier)\n",
    "            input()\n",
    "    out = \"\".join([f\"{t} \" if b else t for t, b in zip(caption, space)])\n",
    "    return out\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"/run/user/1001/gvfs/sftp:host=158.109.8.116,port=22345,user=esanchez/data2fast/users/esanchez/laion/train_coincidences.csv\", sep='\\t')\n",
    "df = df[df['LANGUAGE'] == 'es']\n",
    "\n",
    "tagger = SequenceTagger.load(\"flair/ner-multi-fast\")\n",
    "\n",
    "token = {'LOC': '<loc>', 'ORG': '<org>', 'PER': '<per>', 'MISC': '<misc>'}\n",
    "\n",
    "handler = open('train_ner.tsv', 'w')\n",
    "handler.write(\"SAMPLE_ID\\tURL\\tTEXT\\tHEIGHT\\tWIDTH\\tLICENSE\\tLANGUAGE\\tNSFW\\tsimilarity\\n\")\n",
    "\n",
    "for data in tqdm(df.values):\n",
    "    _, sample_id, url, text, height, width, license, language, nsfw, similarity = data\n",
    "    caption = ner_sentence(text, tagger)\n",
    "    handler.write(f\"{sample_id}\\t{url}\\t{caption}\\t{height}\\t{width}\\t{license}\\t{language}\\t{nsfw}\\t{similarity}\\n\")\n",
    "\n",
    "handler.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc865f53ee3eb6f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Afegir NER a dades LAION (fr, it)\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "device = 'cuda:3'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"Babelscape/wikineural-multilingual-ner\")\n",
    "\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, grouped_entities=True, device=3)\n",
    "\n",
    "token = {'LOC': '<loc>', 'ORG': '<org>', 'PER': '<per>', 'MISC': '<misc>'}\n",
    "\n",
    "def masked_string(example, nlp):\n",
    "    results = nlp(example)\n",
    "    ll = [*example]\n",
    "    shift = 0\n",
    "    for mask in results:\n",
    "        aux = ll[mask['end'] + shift:]\n",
    "        ll[mask['start'] + shift:mask['start'] + len(token[mask['entity_group']]) + shift] = [*token[mask['entity_group']]]\n",
    "        ll = ll[:mask['start'] + len(token[mask['entity_group']]) + shift] + aux\n",
    "        shift = (mask['start'] + len(token[mask['entity_group']])) - mask['end'] + shift\n",
    "    return ''.join(ll)\n",
    "\n",
    "df = pd.read_csv(\"/data2fast/users/esanchez/laion/train_coincidences.csv\", sep='\\t')\n",
    "df = df[(df['LANGUAGE'] == 'fr') | (df['LANGUAGE'] == 'it')]\n",
    "\n",
    "handler = open('/data2fast/users/esanchez/laion/train_ner_fr_it.tsv', 'w')\n",
    "handler.write(\"SAMPLE_ID\\tURL\\tTEXT\\tHEIGHT\\tWIDTH\\tLICENSE\\tLANGUAGE\\tNSFW\\tsimilarity\\n\")\n",
    "\n",
    "for data in tqdm(df.values):\n",
    "    _, sample_id, url, text, height, width, license, language, nsfw, similarity = data\n",
    "    caption = masked_string(text, nlp)\n",
    "    handler.write(f\"{sample_id}\\t{url}\\t{caption}\\t{height}\\t{width}\\t{license}\\t{language}\\t{nsfw}\\t{similarity}\\n\")\n",
    "\n",
    "handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f9711b-d3b3-4a19-a9b8-4357bb62d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traduir descripcions COCO a es, de, nl, it\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "device = \"cuda:0\"\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\").to(device)\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "model.eval()\n",
    "\n",
    "df = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test.tsv\", sep=\"\\t\")\n",
    "\n",
    "class SentenceGetter:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        i = 0\n",
    "        while i < len(self.data['caption']):\n",
    "            yield self.data.iloc[i:i+self.batch_size]\n",
    "            i += self.batch_size\n",
    "    \n",
    "sent_loader = SentenceGetter(df, 32)\n",
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "tokenizer.src_lang = \"en\"\n",
    "\n",
    "for lang in [\"nl\", \"de\", \"es\", \"it\"]:\n",
    "\n",
    "    handler = open(f\"/data2fast/users/esanchez/coco2017/captions_test_{lang}.tsv\", \"a\")\n",
    "    handler.write(\"image\\tcaption\\n\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in sent_loader:\n",
    "            images = list(data['image'])\n",
    "            sentences = list(data['caption'])\n",
    "            encoded_hi = tokenizer(sentences, **tokenizer_kwargs, return_tensors=\"pt\").to(device)\n",
    "            generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(lang), max_length=180)\n",
    "            output = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "            handler.write(\"\".join([f\"{im}\\t{cap}\\n\" for im, cap in zip(images, output)]))\n",
    "            del images, sentences, encoded_hi, generated_tokens, output\n",
    "            torch.cuda.empty_cache()  # Alliberar memòria GPU innecessària\n",
    "    \n",
    "    handler.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2699d2-ad45-4500-a218-54c80dadcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular CLIP-score i CLIP-std\n",
    "import timm\n",
    "import open_clip\n",
    "import math \n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "## Carregar model\n",
    "device = \"cuda:6\"\n",
    "\n",
    "model, preprocess = open_clip.create_model_from_pretrained('hf-hub:timm/ViT-B-16-SigLIP-i18n-256')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:timm/ViT-B-16-SigLIP-i18n-256')\n",
    "\n",
    "## Definir dataloaders\n",
    "class SampleLoader:\n",
    "    def __init__(self, data, dataset_name, tokenizer, batch_size=64):\n",
    "        self.data = data\n",
    "        self.dataset_name = dataset_name\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > len(self):\n",
    "            raise IndexError\n",
    "        sample = self.data.iloc[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        if self.dataset_name in ['coco', 'xac', 'crossmodal', 'vs']:\n",
    "            text = sample['caption']\n",
    "        else:\n",
    "            text = sample['TEXT']\n",
    "        text = self.tokenizer(list(text))\n",
    "        return text\n",
    "\n",
    "class ImageTextLoader:\n",
    "    def __init__(self, data, dataset_name, preprocess, tokenizer, batch_size=64):\n",
    "        self.data = data\n",
    "        self.dataset_name = dataset_name\n",
    "        self.preprocess = preprocess\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        if self.dataset_name == 'coco':\n",
    "            self.path = 'coco/train'\n",
    "        elif self.dataset_name == 'xac':\n",
    "            self.path = 'xac/images'\n",
    "        elif self.dataset_name == 'laion':\n",
    "            self.path = 'laion/img_size'\n",
    "        elif self.dataset_name == 'crossmodal':\n",
    "            self.path = 'laion/crossmodal_imgs'\n",
    "        else:\n",
    "            self.path = 'historic_sd/images'\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data) / self.batch_size)\n",
    "\n",
    "    def _process(self, path):\n",
    "        if self.dataset_name in ['laion', 'crossmodal']:\n",
    "            return str(path) + '.jpg'\n",
    "        elif self.dataset_name == 'vs':\n",
    "            dir_id = int(path) // 4096\n",
    "            return os.path.join(str(dir_id), str(image_id) + '.jpg')\n",
    "        return str(path)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx > len(self):\n",
    "            raise IndexError\n",
    "        sample = self.data.iloc[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        if self.dataset_name in ['coco', 'xac', 'vs']:\n",
    "            text, images = sample['caption'], sample['image']\n",
    "        elif self.dataset_name == 'laion':\n",
    "            text, images = sample['TEXT'], sample['SAMPLE_ID']\n",
    "        else:\n",
    "            text, images = sample['caption'], sample['image/key']\n",
    "        text = self.tokenizer(list(text))\n",
    "        images_out = list()\n",
    "        for image in images:\n",
    "            if self.dataset_name == 'coco':\n",
    "                try:\n",
    "                    path = os.path.join(\"/data2fast/users/esanchez/coco2017/train\", self._process(image))\n",
    "                    img = Image.open(path)\n",
    "                except:\n",
    "                    path = os.path.join(\"/data2fast/users/esanchez/coco2017/test\", self._process(image))\n",
    "                    img = Image.open(path)\n",
    "            else:\n",
    "                path = os.path.join(\"/data2fast/users/esanchez/\", self.path, self._process(image))\n",
    "                img = Image.open(path)\n",
    "            images_out.append(img)\n",
    "        images = [self.preprocess(image) for image in images_out]\n",
    "        images = torch.stack(images)\n",
    "        return text, images\n",
    "\n",
    "\n",
    "## Definir funcions per obtenir mètriques\n",
    "def get_CLIP_score(dataset, dataset_name, batch_size=32):  # xac, coco, laion, crossmodal, vs\n",
    "    dataset = ImageTextLoader(dataset, dataset_name, preprocess, tokenizer, batch_size)\n",
    "    dataloader = DataLoader(dataset, num_workers=8)\n",
    "    \n",
    "    scores = list()\n",
    "    for samples in tqdm(dataloader):\n",
    "        text, images = samples\n",
    "        images = images.squeeze().to(device)\n",
    "        text = text.squeeze().to(device)\n",
    "\n",
    "        if len(images.shape) < 4:\n",
    "            images = images.unsqueeze(0)\n",
    "            text = text.unsqueeze(0)\n",
    "        \n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            image_features = model.encode_image(images).to(device)\n",
    "            text_features = model.encode_text(text)\n",
    "    \n",
    "            # Normalize the features\n",
    "            image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "            text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "            \n",
    "            # Calculate the cosine similarity to get the CLIP score\n",
    "            clip_score = torch.mean(torch.matmul(image_features, text_features.T)[torch.eye(image_features.shape[0], dtype=torch.bool)])\n",
    "            scores.append(clip_score)\n",
    "    scores = torch.stack(scores)\n",
    "    mean_score = torch.mean(scores).item()\n",
    "    return mean_score\n",
    "\n",
    "def get_CLIP_std(dataset, dataset_name, batch_size=256):\n",
    "    dataloader = SampleLoader(dataset, dataset_name, tokenizer, batch_size)\n",
    "    \n",
    "    features = list()\n",
    "    for samples in tqdm(dataloader):\n",
    "        text = samples.to(device)\n",
    "        \n",
    "        with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "            text_features = model.encode_text(text)\n",
    "            features.append(text_features)\n",
    "    features = torch.cat(features, dim=0)\n",
    "    features = features.to('cpu', torch.float32)\n",
    "    mean_features = torch.mean(features, 0)\n",
    "    dif_features = torch.cdist(features, mean_features.unsqueeze(0), p=2)\n",
    "    var = torch.mean(dif_features).item()\n",
    "    std = math.sqrt(var)\n",
    "    return std\n",
    "\n",
    "\n",
    "## Carregar dades\n",
    "laion = pd.read_csv(\"/data2fast/users/esanchez/laion/train_coincidences.csv\", sep=\"\\t\")\n",
    "laion_ner = pd.read_csv(\"/data2fast/users/esanchez/laion/train_ner.tsv\", sep=\"\\t\")\n",
    "xac = pd.read_csv(\"/data2fast/users/esanchez/xac/captions.tsv\", sep=\"\\t\")\n",
    "xac_ner = pd.read_csv(\"/data2fast/users/esanchez/xac/captions_ner.tsv\", sep=\"\\t\")\n",
    "coco = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train.tsv\", sep=\"\\t\")\n",
    "coco_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test.tsv\", sep=\"\\t\")\n",
    "crossmodal = pd.read_csv(\"/data2fast/users/esanchez/laion/captions.tsv\", sep=\"\\t\")\n",
    "\n",
    "languages = ['es', 'ca', 'it', 'en', 'de', 'nl']\n",
    "laion = laion[[lang in languages for lang in laion['LANGUAGE']]]\n",
    "laion_ner = laion_ner[[lang in languages for lang in laion_ner['LANGUAGE']]]\n",
    "coco = pd.concat([coco, coco_2])\n",
    "\n",
    "vs_cat = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train_cat.tsv\", sep=\"\\t\")\n",
    "vs_cat_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test_cat.tsv\", sep=\"\\t\")\n",
    "vs_es = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train_es.tsv\", sep=\"\\t\")\n",
    "vs_es_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test_es.tsv\", sep=\"\\t\")\n",
    "vs_de = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train_de.tsv\", sep=\"\\t\")\n",
    "vs_de_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test_de.tsv\", sep=\"\\t\")\n",
    "vs_nl = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train_nl.tsv\", sep=\"\\t\")\n",
    "vs_nl_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test_nl.tsv\", sep=\"\\t\")\n",
    "vs_it = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_train_it.tsv\", sep=\"\\t\")\n",
    "vs_it_2 = pd.read_csv(\"/data2fast/users/esanchez/coco2017/captions_test_it.tsv\", sep=\"\\t\")\n",
    "\n",
    "vs = pd.concat([vs_cat, vs_cat_2, vs_es, vs_es_2, vs_de, vs_de_2, vs_nl, vs_nl_2, vs_it, vs_it_2])\n",
    "\n",
    "## Calcular mètriques\n",
    "score = get_CLIP_std(xac, 'xac', 256)\n",
    "print('CLIP Std XAC:', score)\n",
    "\n",
    "score = get_CLIP_score(xac, 'xac', 32)\n",
    "print('CLIP Score XAC', score)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c8c46ea3-3531-493b-8bec-b2df0ed413f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/esanchez/miniconda3/envs/xac-ic/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326455387ac44d57a281c882daa1f8d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/913 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gràfica cua pesada NER XAC\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"projecte-aina/roberta-base-ca-cased-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"projecte-aina/roberta-base-ca-cased-ner\")\n",
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "    \n",
    "class SentenceGetter:\n",
    "    def __init__(self, data, batch_size):\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) // self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        i = 0\n",
    "        while i < len(self.data):\n",
    "            yield self.data.iloc[i:i+self.batch_size]\n",
    "            i += self.batch_size\n",
    "\n",
    "df = pd.read_csv(\"/data2fast/users/esanchez/xac/captions.tsv\", sep=\"\\t\")\n",
    "df = df[\"caption\"]\n",
    "\n",
    "dataloader = SentenceGetter(df, 32)\n",
    "ne = list()\n",
    "\n",
    "for batch in tqdm.notebook.tqdm(dataloader):\n",
    "    frases = list(batch)\n",
    "    maskeds = nlp(frases)\n",
    "\n",
    "    for tokens in maskeds:\n",
    "        aux = None\n",
    "        for token in tokens:\n",
    "            if aux is None:\n",
    "                aux = token['word'].replace(\"Ġ\", \" \")\n",
    "            else:\n",
    "                if token['entity'][0] == 'B':\n",
    "                    ne.append(aux)\n",
    "                    aux = token['word'].replace(\"Ġ\", \" \")\n",
    "                else:\n",
    "                    aux += token['word'].replace(\"Ġ\", \" \")\n",
    "        if aux is not None:\n",
    "            ne.append(aux)\n",
    "\n",
    "from collections import Counter\n",
    "count = Counter(ne)\n",
    "count = sorted(count.values(), reverse=True)\n",
    "\n",
    "p = sns.lineplot(count)\n",
    "plt.xticks([0, 5000, 10000, 13256], [0, 5000, 10000, 13256])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Unique named entities\")\n",
    "fig = p.get_figure()\n",
    "fig.savefig(\"tail.svg\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
